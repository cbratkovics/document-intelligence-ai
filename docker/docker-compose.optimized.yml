version: '3.8'

services:
  # Base API service (without ML models)
  app-base:
    build:
      context: ..
      dockerfile: docker/Dockerfile.optimized
      target: runtime-base
    image: document-intelligence-ai:base
    ports:
      - "8000:8000"
    environment:
      - OPENAI_API_KEY=${OPENAI_API_KEY}
      - REDIS_URL=redis://redis:6379
      - CHROMA_HOST=chromadb
      - CHROMA_PORT=8000
      - MODEL_CACHE_DIR=/app/models
      - USE_LOCAL_EMBEDDINGS=false
    depends_on:
      - redis
      - chromadb
    volumes:
      - ../src:/app/src
      - ../data:/app/data
      - app-logs:/app/logs
      - ml-models:/app/models
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8000/health"]
      interval: 30s
      timeout: 10s
      retries: 3
    profiles:
      - base

  # ML-enabled API service
  app-ml:
    build:
      context: ..
      dockerfile: docker/Dockerfile.optimized
      target: runtime-ml
    image: document-intelligence-ai:ml
    ports:
      - "8000:8000"
    environment:
      - OPENAI_API_KEY=${OPENAI_API_KEY}
      - REDIS_URL=redis://redis:6379
      - CHROMA_HOST=chromadb
      - CHROMA_PORT=8000
      - MODEL_CACHE_DIR=/app/models
      - USE_LOCAL_EMBEDDINGS=true
    depends_on:
      - redis
      - chromadb
    volumes:
      - ../src:/app/src
      - ../data:/app/data
      - app-logs:/app/logs
      - ml-models:/app/models
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8000/health"]
      interval: 30s
      timeout: 10s
      retries: 3
    profiles:
      - ml
      - default

  # Development service
  app-dev:
    build:
      context: ..
      dockerfile: docker/Dockerfile.optimized
      target: development
    image: document-intelligence-ai:dev
    ports:
      - "8000:8000"
      - "8888:8888"  # Jupyter
    environment:
      - OPENAI_API_KEY=${OPENAI_API_KEY}
      - REDIS_URL=redis://redis:6379
      - CHROMA_HOST=chromadb
      - CHROMA_PORT=8000
      - MODEL_CACHE_DIR=/app/models
      - USE_LOCAL_EMBEDDINGS=true
    depends_on:
      - redis
      - chromadb
    volumes:
      - ../src:/app/src
      - ../tests:/app/tests
      - ../data:/app/data
      - app-logs:/app/logs
      - ml-models:/app/models
    profiles:
      - dev

  # Model initialization service
  model-init:
    build:
      context: ..
      dockerfile: docker/Dockerfile.optimized
      target: runtime-ml
    image: document-intelligence-ai:ml
    command: python /app/scripts/init_models.py --init
    environment:
      - MODEL_CACHE_DIR=/app/models
    volumes:
      - ml-models:/app/models
    profiles:
      - init

  redis:
    image: redis:7-alpine
    ports:
      - "6379:6379"
    volumes:
      - redis-data:/data
    healthcheck:
      test: ["CMD", "redis-cli", "ping"]
      interval: 10s
      timeout: 5s
      retries: 5

  chromadb:
    image: chromadb/chroma:0.4.22
    ports:
      - "8001:8000"
    environment:
      - IS_PERSISTENT=TRUE
      - PERSIST_DIRECTORY=/chroma/chroma
    volumes:
      - chroma-data:/chroma/chroma
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8000/api/v1/heartbeat"]
      interval: 10s
      timeout: 5s
      retries: 5

  prometheus:
    image: prom/prometheus:latest
    ports:
      - "9090:9090"
    volumes:
      - ./prometheus.yml:/etc/prometheus/prometheus.yml
      - prometheus-data:/prometheus
    command:
      - '--config.file=/etc/prometheus/prometheus.yml'
      - '--storage.tsdb.path=/prometheus'
    depends_on:
      - app-ml
    profiles:
      - monitoring

  grafana:
    image: grafana/grafana:latest
    ports:
      - "3000:3000"
    environment:
      - GF_SECURITY_ADMIN_USER=admin
      - GF_SECURITY_ADMIN_PASSWORD=admin
      - GF_USERS_ALLOW_SIGN_UP=false
    volumes:
      - grafana-data:/var/lib/grafana
    depends_on:
      - prometheus
    profiles:
      - monitoring

volumes:
  redis-data:
  chroma-data:
  prometheus-data:
  grafana-data:
  app-logs:
  ml-models:
    driver: local
    driver_opts:
      type: none
      o: bind
      device: ${PWD}/../models