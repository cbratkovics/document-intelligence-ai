# Multi-stage optimized Dockerfile for Document Intelligence AI
# Target: < 1GB total size with no layer > 500MB

# Build stage - for building Python wheels and cleaning up
FROM python:3.11-slim as builder

# Install build dependencies
RUN apt-get update && \
    apt-get install -y --no-install-recommends \
    build-essential \
    gcc \
    g++ \
    libgomp1 \
    && rm -rf /var/lib/apt/lists/*

# Create wheel directory
RUN mkdir -p /wheels

# Copy requirements files
COPY requirements-base.txt requirements-ml.txt /tmp/

# Build wheels for base dependencies first (smaller layer)
RUN pip wheel --no-cache-dir --no-deps --wheel-dir /wheels/base -r /tmp/requirements-base.txt

# Build wheels for ML dependencies (can be optional)
RUN pip wheel --no-cache-dir --no-deps --wheel-dir /wheels/ml -r /tmp/requirements-ml.txt

# Runtime stage - minimal image for running the application
FROM python:3.11-slim as runtime

# Install only essential runtime dependencies
RUN apt-get update && \
    apt-get install -y --no-install-recommends \
    libgomp1 \
    curl \
    && rm -rf /var/lib/apt/lists/* \
    && apt-get clean

# Create app user and directories
RUN useradd -m -u 1000 appuser && \
    mkdir -p /app/src /app/data /app/logs /app/models && \
    chown -R appuser:appuser /app

WORKDIR /app

# Copy and install base wheels
COPY --from=builder /wheels/base /tmp/wheels/base
RUN pip install --no-cache-dir --no-index --find-links /tmp/wheels/base /tmp/wheels/base/*.whl && \
    rm -rf /tmp/wheels/base

# Copy application code
COPY --chown=appuser:appuser src/ /app/src/
COPY --chown=appuser:appuser scripts/ /app/scripts/

# Set environment variables
ENV PYTHONPATH=/app \
    PYTHONUNBUFFERED=1 \
    PYTHONDONTWRITEBYTECODE=1 \
    MODEL_CACHE_DIR=/app/models \
    HF_HOME=/app/models \
    TRANSFORMERS_CACHE=/app/models

# Switch to non-root user
USER appuser

# Expose port
EXPOSE 8000

# Health check
HEALTHCHECK --interval=30s --timeout=30s --start-period=5s --retries=3 \
    CMD curl -f http://localhost:8000/health || exit 1

# Run the application with model initialization
CMD ["python", "scripts/init_models.py", "&&", "python", "-m", "uvicorn", "src.api.main:app", "--host", "0.0.0.0", "--port", "8000"]

# ML-enabled stage - includes ML dependencies for local model inference
FROM runtime as ml-runtime

# Copy and install ML wheels
COPY --from=builder /wheels/ml /tmp/wheels/ml
RUN pip install --no-cache-dir --no-index --find-links /tmp/wheels/ml /tmp/wheels/ml/*.whl && \
    rm -rf /tmp/wheels/ml

# Development stage - includes development tools and dependencies
FROM ml-runtime as dev-runtime

# Switch back to root for package installation
USER root

# Install development dependencies
RUN apt-get update && \
    apt-get install -y --no-install-recommends \
    git \
    vim \
    htop \
    && rm -rf /var/lib/apt/lists/*

# Copy dev requirements and install
COPY requirements-dev.txt /tmp/
RUN pip install --no-cache-dir -r /tmp/requirements-dev.txt && \
    rm /tmp/requirements-dev.txt

# Switch back to app user
USER appuser

# Override CMD for development with hot reload
CMD ["python", "-m", "uvicorn", "src.api.main:app", "--host", "0.0.0.0", "--port", "8000", "--reload"]